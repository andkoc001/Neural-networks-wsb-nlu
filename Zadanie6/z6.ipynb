{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "800185ce",
   "metadata": {},
   "source": [
    "# Zadanie 6\n",
    "> Andrzej Kocielski, 09.12.2023\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22a5c2",
   "metadata": {},
   "source": [
    "Wracamy do bazy danych MNIST, która jest publicznie dostępnym zbiorem danych składającym się z obrazów odręcznych pojedynczych cyfr. Każdy obraz ma kwadrat o wymiarach 28 na 28 pikseli, co oznacza, że każdy z nich ma łącznie 784 piksele. Użyjemy standardowego podziału zestawu danych, który wynosi 60 000 obrazów do trenowania naszego modelu i 10 000 do testowania naszego modelu. Celem jest rozpoznawanie cyfr pisanych odręcznie, co oznacza, że mamy do przewidzenia 10 klas (od 0 do 9). Naszym celem będzie wytrenowanie sieci neuronowej tak, aby osiągała mniej niż 1% błędu predykcji lub 99%+ dokładności.\n",
    "Do zbudowania tej sieci neuronowej użyjemy bezpłatnego, opartego na chmurze, obsługującego procesor graficzny środowiska notebooka [Jupyter: Google Colab](https://colab.research.google.com/drive/1lgm4TmAIihDNLso2jooorbkC5bJXp4BV?authuser=1#scrollTo=fSyZvnYn2m0e). Zacznijmy od zaimportowania zestawu danych MNIST, który jest wygodnie dostarczany przez bibliotekę Keras.\n",
    "Zaimportujemy również klasy i funkcje, których będziemy potrzeb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf62b413",
   "metadata": {},
   "source": [
    "Zaimportujemy również klasy i funkcje, których będziemy potrzebować:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9377880-3bbf-4c6a-9345-2d13de8a40dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.datasets \n",
    "import keras.models \n",
    "from keras.models import Sequential # model of ANN\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation # layers of ANN\n",
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "from keras import backend as K\n",
    "\n",
    "# import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75251960",
   "metadata": {},
   "source": [
    "Następnie podzielimy dane między zestawy treningowe i testowe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f61a6514",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de40fd42",
   "metadata": {},
   "source": [
    "Następnie zaimportujemy bibliotekę Matplotlib na potrzeby wizualizacji danych i wykreślimy pierwsze 2 obrazy w zestawie danych treningowych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c39bde",
   "metadata": {},
   "source": [
    "P4: Wyjaśnij znaczenie \"Współdzielenia parametrów\" i \"Rzadkości połączeń\" w CNN.\n",
    "\n",
    "Odp (Andrzej Kocielski):\n",
    "Współdzielenie wag – wspólny zestaw wag (+ bias) dla wszystkich lokalnych pól receptywnych. → w efekcie, warstwa konwolucji nauczy  się rozpoznawać pewną (losową) cechę w obrazie.\n",
    "\n",
    "Rzadkość połączeń - w przeciwieństwie do \"gęstych\" warstw, gdzie każdy neuron jest połączony z każdym, w CNN ma zastosowanie agregacja cech (pooling), tak iż nie połączeń jest mniej. Przykładow dobierana jest największa wartość (funkcja max) lub suma pierw. kwadratowego (funkcja L2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1286bdf4-0be9-405b-8acf-d7a728e77ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 2 images as gray scale\n",
    "plt.figure(figure=(7,7))\n",
    "plt.imshow(X_train[0], cmap=plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053bb8db",
   "metadata": {},
   "source": [
    "Zaczniemy od ustawienia parametrów tuningu modelu w następujący sposób:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a4e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = ???\n",
    "num_classes =  ???\n",
    "epochs = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a2ab5",
   "metadata": {},
   "source": [
    "Następnie spłaszczymy nasz zestaw danych z obrazów o strukturze 28 na 28 pikseli do wektora, który ma wartości wejściowe 784 pikseli.Najpierw wprowadzimy wymiary naszego obrazu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d32694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8447935d",
   "metadata": {},
   "source": [
    "Znormalizujemy również wartości pikseli od skali szarości, która mieści się w zakresie od 0 do 255, do zakresu od 0 do 1. Robimy to, dzieląc każdy z nich przez 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10003654",
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first': \n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols) \n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else: \n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1) \n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'training samples')\n",
    "print(X_test.shape[0], 'testing samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366709c7",
   "metadata": {},
   "source": [
    "Ponieważ jest to problem klasyfikacji wieloklasowej (0-9), spowoduje to konwersję wektorów klas na macierze klas binarnych.\n",
    "\n",
    "Załóżmy na przykład, że cyfrą jest 2, przekonwertujemy wektor z [0 1 2 3 4 5 6 7 8 9] na [0 0 1 0 0 0 0 0 0 0 0 0]. Użyjemy wbudowanej funkcji, którą zapewnia Keras.utils.to_categorical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = ???\n",
    "y_test = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d0ccf",
   "metadata": {},
   "source": [
    "Zdefiniujemy teraz nasz model sieci neuronowej, który, jak wspomniano, będzie używał TensorFlow jako zaplecza modelu. Struktura naszej konwolucyjnej architektury sieci neuronowej jest zdefiniowana następująco:\n",
    "- Pierwsza ukryta warstwa to warstwa konwolucyjna, która ma 32 mapy obiektów, każda o rozmiarze 3 x 3 i używamy wyprostowanej funkcji aktywacji liniowej - .Conv2Drelu\n",
    "- Następnie dodajemy kolejną warstwę konwolucyjną z 64 mapami obiektów\n",
    "- Dodajemy trzecią warstwę konwolucyjną ze 128 mapami obiektów\n",
    "- Następnie dodajemy warstwę puli, która jest skonfigurowana z rozmiarem puli 2 x 2MaxPooling2D1\n",
    "\n",
    "Następnie nakładamy warstwę regularyzacyjną, która jest ustawiona tak, aby losowo wykluczyć 25% neuronów w warstwie - służy to do zmniejszenia nadmiernego dopasowaniaDropout\n",
    "Następnie przekształcamy macierz 2-wymiarową w wektor za pomocą - pozwala to na przetwarzanie naszego wyjścia przez w pełni połączone warstwyFlatten\n",
    "Następnie dodajemy w pełni połączoną warstwę, która ma 128 neuronów i funkcję aktywacji ReLU\n",
    "Następnie dodamy kolejną warstwę regularyzacji, aby zmniejszyć nadmierne dopasowanie, tym razem losowo wykluczamy 50% neuronów\n",
    "\n",
    "Kończymy sieć neuronową warstwą wyjściową, która ma 10 neuronów - tyle samo, ile klas w naszym problemie klasyfikacyjnym i funkcję aktywacji softmax. Spowoduje to wyświetlenie przewidywania prawdopodobieństwa, że cyfra należy do każdej klasy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1693f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import TensorFlow backend\n",
    "import tensorflow as tf\n",
    "# define our model\n",
    "model = Sequential()\n",
    "???\n",
    "???\n",
    "???\n",
    "???\n",
    "???\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation=Activation(tf.nn.softmax)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7254b48",
   "metadata": {},
   "source": [
    "Następnie skompilujemy nasz model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "\t\toptimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4ccf5b",
   "metadata": {},
   "source": [
    "Teraz dopasujemy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "???\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b7498e",
   "metadata": {},
   "source": [
    "\n",
    "Na koniec ocenimy nasz model i wydrukujemy dokładność:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b43016",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "???\n",
    "???\n",
    "???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
