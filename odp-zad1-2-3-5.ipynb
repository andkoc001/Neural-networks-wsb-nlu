{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8434e248-b5c4-4f32-a73e-731130aba2b0",
   "metadata": {},
   "source": [
    "# Odpowiedzi na zadania laboratoryjne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b80c00-fca5-446f-a2a3-da67f2a042c0",
   "metadata": {},
   "source": [
    "## Zadanie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53575a-47ed-4285-bc95-d60a87cecac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zestaw 1 zad.1\n",
    "\n",
    "import numpy as np\n",
    "class SimpleNeuralNetwork:\n",
    "\n",
    "    def __init__(self):\n",
    "        np.random.seed(1)\n",
    "        self.weights = 2 * np.random.random((3, 1)) - 1\n",
    " \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def d_sigmoid(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def train(self, train_input, train_output, train_iters):\n",
    "        for _ in range(train_iters):\n",
    "            propagation_result = self.propagation(train_input)\n",
    "            self.backward_propagation(\n",
    "                propagation_result, train_input, train_output)\n",
    "\n",
    "    def propagation(self, inputs):\n",
    "        \"\"\"\n",
    "        Propagation process\n",
    "        \"\"\"\n",
    "        return self.sigmoid(np.dot(inputs.astype(float), self.weights))\n",
    "\n",
    "    def backward_propagation(self, propagation_result, train_input, train_output):\n",
    "        \"\"\"\n",
    "        Backward propagation process \n",
    "        \"\"\"\n",
    "        error = train_output - propagation_result\n",
    "        self.weights += np.dot(\n",
    "            train_input.T, error * self.d_sigmoid(propagation_result)\n",
    "        )\n",
    " \n",
    "network = SimpleNeuralNetwork()\n",
    "\n",
    "print(network.weights)\n",
    "\n",
    "train_inputs = np.array(\n",
    "    [[1, 1, 0], [1, 1, 1], [1, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], ]\n",
    "                       )\n",
    "\n",
    "train_outputs = np.array([[0, 1, 0, 0, 1, 0]]).T\n",
    "\n",
    "train_iterations = 50000\n",
    "\n",
    "network.train(train_inputs, train_outputs, train_iterations)\n",
    "\n",
    "print(network.weights)\n",
    "\n",
    "test_data = np.array([[1, 1, 1], [1, 0, 0], [0, 1, 1], [0, 1, 0], ])\n",
    "\n",
    "for data in test_data:\n",
    "    print(f\"Wynikiem dla danych {data} jest:\")\n",
    "    print(network.propagation(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1206ff1-bf58-492d-8790-826736e4e996",
   "metadata": {},
   "source": [
    "## Zadanie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf2caf-403e-45d5-a1be-a5304790d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zestaw 1-2 zad.2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "CarPricesDataNumeric=pd.read_pickle('CarPricesData.pkl')\n",
    "CarPricesDataNumeric.head()\n",
    "\n",
    "TargetVariable=['Price']\n",
    "Predictors=['Age', 'KM', 'Weight', 'HP', 'MetColor', 'CC', 'Doors']\n",
    "\n",
    "X = CarPricesDataNumeric[Predictors].values\n",
    "y = CarPricesDataNumeric[TargetVariable].values\n",
    " \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "PredictorScaler = StandardScaler()\n",
    "TargetVarScaler = StandardScaler()\n",
    "\n",
    "PredictorScalerFit = PredictorScaler.fit(X)\n",
    "TargetVarScalerFit = TargetVarScaler.fit(y)\n",
    "\n",
    "X = PredictorScalerFit.transform(X)\n",
    "y = TargetVarScalerFit.transform(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#ANN model\n",
    "model = Sequential()\n",
    "\n",
    "# the Input layer and first hidden layer\n",
    "model.add(Dense(units=5, input_dim=7, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "#the Second layer of the model\n",
    "model.add(Dense(units=5, kernel_initializer='normal', activation='tanh'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train ,batch_size = 20, epochs = 50, verbose=1)\n",
    "\n",
    "# Tuning of parameters\n",
    "def FunctionFindBestParams(X_train, y_train, X_test, y_test):\n",
    "    # Defining the list of hyper parameters to try\n",
    "    batch_size_list = [5, 10, 15, 20]\n",
    "    epoch_list = [5, 10, 50, 100]\n",
    "\n",
    "    SearchResultsData = pd.DataFrame(columns=['TrialNumber', 'Parameters', 'Accuracy'])\n",
    "\n",
    "    # initializing the trials\n",
    "    TrialNumber = 0\n",
    "\n",
    "    for batch_size_trial in batch_size_list:\n",
    "        for epochs_trial in epoch_list:\n",
    "            TrialNumber += 1\n",
    "\n",
    "            # create ANN model\n",
    "            model = Sequential()\n",
    "\n",
    "            # the first layer of the model\n",
    "            model.add(Dense(units=5, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # the Second layer of the model\n",
    "            model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # The output neuron is a single fully connected node \n",
    "            model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "            # Fitting the ANN to the Training set\n",
    "            model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=0)\n",
    "\n",
    "            MAPE = np.mean(100 * (np.abs(y_test-model.predict(X_test))/y_test))\n",
    "\n",
    "            # printing the results of the current iteration\n",
    "            print(TrialNumber, 'Parameters:','batch_size:', batch_size_trial,'-', 'epochs:',epochs_trial, 'Accuracy:', 100-MAPE)\n",
    "\n",
    "            SearchResultsData=SearchResultsData.append(pd.DataFrame(\n",
    "                data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n",
    "                columns=['TrialNumber', 'Parameters', 'Accuracy'])\n",
    "                                                      )\n",
    "\n",
    "    return(SearchResultsData)\n",
    "\n",
    "ResultsData = FunctionFindBestParams(X_train, y_train, X_test, y_test)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#Deep ANN model \n",
    "def make_regression_ann(Optimizer_trial):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=5, input_dim=7, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Optimizer_trial)\n",
    "    return model\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train ,batch_size = 15, epochs = 5, verbose=0)\n",
    "\n",
    "Predictions = model.predict(X_test)\n",
    "\n",
    "# Scaling the predicted Price data back to original price scale\n",
    "Predictions = TargetVarScalerFit.inverse_transform(Predictions)\n",
    "\n",
    "# Scaling the y_test Price data back to original price scale\n",
    "y_test_orig = TargetVarScalerFit.inverse_transform(y_test)\n",
    "\n",
    "print(\"########## Razem: \", round((EndTime-StartTime)/60), 'minut')\n",
    "\n",
    "grid_search.best_params_\n",
    "\n",
    "# Scaling the test data back to original scale\n",
    "Test_Data = PredictorScalerFit.inverse_transform(X_test)\n",
    "\n",
    "TestingData = pd.DataFrame(data=Test_Data, columns=Predictors)\n",
    "TestingData['Price'] = y_test_orig\n",
    "TestingData['PredictedPrice'] = Predictions\n",
    "\n",
    "TestingData.head()\n",
    "\n",
    "# APE\n",
    "APE = 100*(abs(TestingData['Price']-TestingData['PredictedPrice'])/TestingData['Price'])\n",
    "\n",
    "TestingData['APE'] = APE\n",
    "\n",
    "print('The Accuracy of ANN model is:', 100-np.mean(APE))\n",
    "\n",
    "TestingData.head()\n",
    "\n",
    "###########################################\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "Parameter_Trials = {'batch_size':[10,20,30],\n",
    "                      'epochs':[10,20],\n",
    "                    'Optimizer_trial':['adam', 'rmsprop']\n",
    "                   }\n",
    "\n",
    "#ANN model\n",
    "RegModel = KerasRegressor(make_regression_ann, verbose=0)\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def Accuracy_Score(orig,pred):\n",
    "    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))\n",
    "    print('#'*70,'Accuracy:', 100-MAPE)\n",
    "    return(100-MAPE)\n",
    "\n",
    "custom_Scoring = make_scorer(Accuracy_Score, greater_is_better=True)\n",
    "\n",
    "#the Grid search space\n",
    "grid_search = GridSearchCV(estimator=RegModel, \n",
    "                         param_grid=Parameter_Trials, \n",
    "                         scoring=custom_Scoring, \n",
    "                         cv=5)\n",
    "\n",
    "import time\n",
    "StartTime = time.time()\n",
    "\n",
    "grid_search.fit(X,y, verbose=1)\n",
    "\n",
    "EndTime=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11357286-ed79-4c80-bdd9-7ae17f6426b0",
   "metadata": {},
   "source": [
    "## Zadanie 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c3d25b-e35a-448c-99ea-667cdc969cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zestaw 1-2 zad.3\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# wczytanie danych \n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_val, y_val) = fashion_mnist.load_data()\n",
    "\n",
    "print(f'Zbiór uczący: {X_train.shape}, zbiór walidacyjny: {X_val.shape}')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(X_train[0], cmap=plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "def plot_digit(digit, dem=28, font_size=8):\n",
    "    max_ax = font_size * dem\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.xlim([0, max_ax])\n",
    "    plt.ylim([0, max_ax])\n",
    "    plt.axis('off')\n",
    "\n",
    "    for idx in range(dem):\n",
    "        for jdx in range(dem):\n",
    "            t = plt.text(idx*font_size, max_ax - jdx*font_size, \n",
    "                         digit[jdx][idx], fontsize=font_size, \n",
    "                         color=\"#000000\")\n",
    "            c = digit[jdx][idx] / 255.\n",
    "            t.set_bbox(dict(facecolor=(c, c, c), alpha=0.5, \n",
    "                            edgecolor='#f1f1f1'))\n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "plot_digit(X_train[0])\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "for i in range(40):\n",
    "    plt.subplot(5, 8, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[y_train[i]])\n",
    "plt.show()\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_val = X_val.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, len(class_names))\n",
    "y_val = to_categorical(y_val, len(class_names))\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "from tensorflow.keras.layers import Flatten, add\n",
    "\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    batch_size = 256,\n",
    "                    validation_data = (X_val, y_val)\n",
    "                   )\n",
    "\n",
    "def draw_curves(history, key1='accuracy', ylim1=(0.8, 1.00), \n",
    "                key2='loss', ylim2=(0.0, 1.0)):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[key1], \"r--\")\n",
    "    plt.plot(history.history['val_' + key1], \"g--\")\n",
    "    plt.ylabel(key1)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylim(ylim1)\n",
    "    plt.legend(['train', 'test'], loc='best')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[key2], \"r--\")\n",
    "    plt.plot(history.history['val_' + key2], \"g--\")\n",
    "    plt.ylabel(key2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylim(ylim2)\n",
    "    plt.legend(['train', 'test'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "draw_curves(history, key1='accuracy', ylim1=(0.7, 0.95), \n",
    "            key2='loss', ylim2=(0.0, 0.8))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757cfbb1-ae30-446d-b79c-a187f09da8cb",
   "metadata": {},
   "source": [
    "## Zadanie 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee4d344-4b32-4825-be03-e21e9952386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zad.5 - najprościej\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Wersja bez tuningu! Polecam przetestować inne opcje - AT\n",
    "\n",
    "seed = 2024\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "dataset = numpy.loadtxt('pima-indians-diabetes.csv', delimiter=\",\")\n",
    "\n",
    "X = dataset[:,0:8]  \n",
    "Y = dataset[:,8]     \n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(500, activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, Y, epochs=150, batch_size=10,  verbose=2) # 150 epoch, 10 batch size, verbose = 2\n",
    "\n",
    "scores = model.evaluate(X, Y)\n",
    "\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "predictions = model.predict(X)    \n",
    "\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab8e01c-3ab0-40bf-aee7-3afd22992211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
